{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc8eb19c-d5f9-455e-8357-b5bebfa7bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Tuple\n",
    "\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import models, layers, losses\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BASE_DATASET_PATH = 'dataset'\n",
    "IMAGE_WIDTH = 299\n",
    "IMAGE_HEIGHT = 299\n",
    "EXAMPLES_QUANTITY = 5400\n",
    "CATEGORIES_QUANTITY = 10\n",
    "TEST_DISTRIBUTION = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1a4c5f7-27c3-4ca9-9316-e0ccfc792113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels_list() -> List[str]:\n",
    "    \"\"\"Get list of labels from txt file.\"\"\"\n",
    "    try:\n",
    "        with open(os.path.join(BASE_DATASET_PATH, 'name of the animals.txt')) as labels_file:\n",
    "            labels = labels_file.read().splitlines()\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError('Incorrect path to \"name of the animals.txt\" file!')\n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c65363fc-35b4-4041-8b5d-c13ab0291d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_array(image_path: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Transform image to numpy array with required standards.\n",
    "\n",
    "    :param image_path: Image path\n",
    "    :return: Image as numpy array\n",
    "    \"\"\"\n",
    "    return cv2.resize(cv2.imread(image_path), (IMAGE_WIDTH, IMAGE_HEIGHT)) / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8695365-8e2c-4961-bee1-d00211654558",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_labels_list()\n",
    "\n",
    "full_dataset_x = np.zeros((EXAMPLES_QUANTITY, IMAGE_WIDTH, IMAGE_HEIGHT, 3))\n",
    "full_dataset_y = np.zeros(EXAMPLES_QUANTITY)\n",
    "samples_counter = 0\n",
    "\n",
    "for label_i, label in enumerate(labels):\n",
    "    label_folder = os.path.join(BASE_DATASET_PATH, 'animals', label)\n",
    "\n",
    "    if not os.path.exists(label_folder):\n",
    "        raise ValueError(f'Dataset doesn\\'t have {label}\\'s folder!')\n",
    "\n",
    "    for filename in os.listdir(label_folder):\n",
    "        example_path = os.path.join(label_folder, filename)\n",
    "\n",
    "        if os.path.isfile(example_path):\n",
    "            image = image_to_array(example_path)\n",
    "\n",
    "            full_dataset_x[samples_counter] = image\n",
    "            full_dataset_y[samples_counter] = label_i\n",
    "\n",
    "            samples_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4a01fe9-367a-44ce-824d-3809eb5d0403",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_x, train_y, test_y = train_test_split(full_dataset_x, full_dataset_y,\n",
    "                                                    test_size=TEST_DISTRIBUTION,\n",
    "                                                    random_state=42, shuffle=True)\n",
    "\n",
    "train_y = to_categorical(train_y, num_classes=CATEGORIES_QUANTITY)\n",
    "test_y = to_categorical(test_y, num_classes=CATEGORIES_QUANTITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22c254b4-69dd-45c1-9d45-f51f0af29988",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=(299, 299, 3))\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e8d7d34-6e89-4ce6-8ae2-fa91636df376",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.04 GiB for an array with shape (3024, 299, 299, 3) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[28], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_x\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai-app-1FgcwWcn-py3.11\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\ai-app-1FgcwWcn-py3.11\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:86\u001B[0m, in \u001B[0;36mconvert_to_eager_tensor\u001B[1;34m(value, ctx, dtype)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Converts the given `value` to an `EagerTensor`.\u001B[39;00m\n\u001B[0;32m     67\u001B[0m \n\u001B[0;32m     68\u001B[0m \u001B[38;5;124;03mNote that this function could return cached copies of created constants for\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;124;03m  TypeError: if `dtype` is not compatible with the type of t.\u001B[39;00m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m     83\u001B[0m   \u001B[38;5;66;03m# Make a copy explicitly because the EagerTensor might share the underlying\u001B[39;00m\n\u001B[0;32m     84\u001B[0m   \u001B[38;5;66;03m# memory with the input array. Without this copy, users will be able to\u001B[39;00m\n\u001B[0;32m     85\u001B[0m   \u001B[38;5;66;03m# modify the EagerTensor after its creation by changing the input array.\u001B[39;00m\n\u001B[1;32m---> 86\u001B[0m   value \u001B[38;5;241m=\u001B[39m value\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, ops\u001B[38;5;241m.\u001B[39mEagerTensor):\n\u001B[0;32m     88\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m value\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m!=\u001B[39m dtype:\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 6.04 GiB for an array with shape (3024, 299, 299, 3) and data type float64"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y, epochs=20, validation_split=0.3, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a80e3c-b2ac-431a-a160-1734e4e87c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(self.test_x, self.test_y, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12459cc2-bd26-4025-ba20-598541af4c40",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4fb8d9-e6c4-4dd2-b8f4-a4ea27d6cc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = image_to_array('butterfly.jpg')\n",
    "image_array = image_array.reshape(1, image_array.shape[0], image_array.shape[1], 3)\n",
    "predict = model.predict(image_array)\n",
    "idx = np.argmax(predict)\n",
    "print(predict)\n",
    "print(idx)\n",
    "print(_get_label(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b94de7-d8f9-4643-ae38-3b150a4ec505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
